{
 "metadata": {
  "name": "",
  "signature": "sha256:d33df5617242336a782e355f89c2fccd369a682804ff575b82041a942291b4e6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Fitting Gaussians to Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\newcommand{\\xv}{\\mathbf{x}}\n",
      "\\newcommand{\\Xv}{\\mathbf{X}}\n",
      "\\newcommand{\\piv}{\\mathbf{\\pi}}\n",
      "\\newcommand{\\yv}{\\mathbf{y}}\n",
      "\\newcommand{\\Yv}{\\mathbf{Y}}\n",
      "\\newcommand{\\zv}{\\mathbf{z}}\n",
      "\\newcommand{\\av}{\\mathbf{a}}\n",
      "\\newcommand{\\Wv}{\\mathbf{W}}\n",
      "\\newcommand{\\wv}{\\mathbf{w}}\n",
      "\\newcommand{\\gv}{\\mathbf{g}}\n",
      "\\newcommand{\\Hv}{\\mathbf{H}}\n",
      "\\newcommand{\\dv}{\\mathbf{d}}\n",
      "\\newcommand{\\Vv}{\\mathbf{V}}\n",
      "\\newcommand{\\vv}{\\mathbf{v}}\n",
      "\\newcommand{\\tv}{\\mathbf{t}}\n",
      "\\newcommand{\\Tv}{\\mathbf{T}}\n",
      "\\newcommand{\\Sv}{\\mathbf{S}}\n",
      "\\newcommand{\\zv}{\\mathbf{z}}\n",
      "\\newcommand{\\Zv}{\\mathbf{Z}}\n",
      "\\newcommand{\\Norm}{\\mathcal{N}}\n",
      "\\newcommand{\\muv}{\\boldsymbol{\\mu}}\n",
      "\\newcommand{\\sigmav}{\\boldsymbol{\\sigma}}\n",
      "\\newcommand{\\phiv}{\\boldsymbol{\\phi}}\n",
      "\\newcommand{\\Phiv}{\\boldsymbol{\\Phi}}\n",
      "\\newcommand{\\Sigmav}{\\boldsymbol{\\Sigma}}\n",
      "\\newcommand{\\Lambdav}{\\boldsymbol{\\Lambda}}\n",
      "\\newcommand{\\half}{\\frac{1}{2}}\n",
      "\\newcommand{\\argmax}[1]{\\underset{#1}{\\operatorname{argmax}}}\n",
      "\\newcommand{\\argmin}[1]{\\underset{#1}{\\operatorname{argmin}}}\n",
      "\\newcommand{\\dimensionbar}[1]{\\underset{#1}{\\operatorname{|}}}\n",
      "$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fitting a Gaussian (Normal) Distribution to Data Samples"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now for the fun part.  How do we adjust the mean and covariance matrix\n",
      "to fit a set of samples?\n",
      "We will do so by defining the likelihood of a set of data for a given\n",
      "model with particular parameter values, and derive\n",
      "the procedure to maximize the likelihood by searching for the best\n",
      "parameter values.\n",
      "\n",
      "Given a set of samples $\\Xv =\\{\\xv_1, \\xv_2, \\ldots, \\xv_N\\}$ and\n",
      "particular values for parameters $\\mu$ and $\\Sigma$, the likelihood of the data\n",
      "is the joint probability over all samples.  If we assume them to be independent of each other, then this is a product of the likelihoods for each sample:\n",
      "$$\n",
      "L(\\Xv;\\muv,\\Sigmav) = \\prod_{n=1}^N \\Norm(\\xv_n|\\muv,\\Sigmav)\n",
      "$$\n",
      "where $\\Norm(\\xv_n|\\muv,\\Sigmav)$ is the value of the Normal\n",
      "distribution function for sample $\\xv_n$.  We want\n",
      "\n",
      "$$\n",
      "\\begin{align*}\n",
      "\\muv, \\Sigmav &= \\argmax{\\muv,\\Sigmav} L(\\Xv;\\muv,\\Sigmav)\\\\\n",
      "\\end{align*}\n",
      "$$\n",
      "\n",
      "How do we find this?  Take derivatives and set equal to zero?  But,\n",
      "taking the derivative of a product of a lot of things gives me a headache.\n",
      "Instead, let's work with the logarithm of the likelihood.  Recall that the logarithm of a product is a sum of the logarithms.  Turns out that the values of $\\muv$ and $\\Sigmav$ that maximize $L(\\Xv ; \\piv,\\muv, \\Sigmav)$ also maximize the logarithm of  $L(\\Xv ; \\muv, \\Sigmav)$.\n",
      "The argmax of\n",
      "the log of the likelihood will give us the same result as the argmax\n",
      "of the likelihood.\n",
      "\n",
      "Which logarithm base should we use?  10?  2?  In applying the logarithm, we often have to apply it to many of the terms in our expression.  Since our expression involves powers of $e$, let's use natural logarithms, $\\ln$. The log liklihood becomes\n",
      "\n",
      "$$\n",
      "\\begin{align*}\n",
      "LL(\\Xv;\\muv,\\Sigmav) &= \\ln \\prod_{n=1}^N \\Norm(\\xv_n|\\muv,\\Sigmav)\\\\\n",
      "&= \\sum_{n=1}^N \\ln \\Norm(\\xv_n|\\muv,\\Sigmav)\\\\\n",
      "& = \\sum_{n=1}^N \\ln \\frac{1}{2\\pi^{D/2} |\\Sigmav |^{1/2}}\n",
      "      e^{-\\frac{1}{2} (\\xv_n-\\muv)^T \\Sigmav^{-1} (\\xv_n - \\muv)}\n",
      "\\end{align*}\n",
      "$$\n",
      "where $D$ is the dimensionality of each sample.\n",
      "\n",
      "Now what?\n",
      "Using your immense memory of logarithms, we get\n",
      "$$\n",
      "\\begin{align*}\n",
      "LL(\\Xv;\\muv,\\Sigmav) &= -\\sum_{n=1}^N \\left ( \\frac{D}{2} \\ln(2\\pi) +\n",
      "\\frac{1}{2} \\ln |\\Sigmav | +\\frac{1}{2} (\\xv_n-\\muv)^T \\Sigmav^{-1} (\\xv_n - \\muv) \\right )\n",
      "\\end{align*}\n",
      "$$\n",
      "\n",
      "Let's simplify this to one-dimensional, or scalar, data samples for now, so $\\Sigmav = \\sigma$ and $\\muv\n",
      "= \\mu$.\n",
      "$$\n",
      "\\begin{align*}\n",
      "LL(x;\\mu,\\sigma) &= -\\sum_{n=1}^N \\left ( \\frac{D}{2} \\ln(2\\pi) +\n",
      "\\frac{1}{2} \\ln \\sigma +\\frac{1}{2} (x_n-\\mu)^2 / \\sigma \\right )\\\\\n",
      "\\frac{\\partial LL(x;\\mu,\\sigma)}{\\partial \\mu} &= -\\sum_{n=1}^N \n",
      "\\left ( \\frac{1}{2} 2 (x_n-\\mu)(-1) / \\sigma \\right ) \\\\\n",
      " &= \\sum_{n=1}^N (x_n-\\mu) / \\sigma \\\\\n",
      "\\end{align*}\n",
      "$$\n",
      "Setting this equal to zero results in\n",
      "$$\n",
      "\\begin{align*}\n",
      "0 &= \\sum_{n=1}^N (x_n-\\mu)(-1) / \\sigma \\\\\n",
      "&=  \\sum_{n=1}^N x_n- \\sum_{n=1}^N \\mu \\\\\n",
      "&=  \\sum_{n=1}^N x_n- N \\mu \\\\\n",
      "\\mu &= \\frac{1}{N} \\sum_{n=1}^N x_n \\\\\n",
      "\\end{align*}\n",
      "$$\n",
      "and\n",
      "$$\n",
      "\\begin{align*}\n",
      "\\frac{\\partial LL(x;\\mu,\\sigma)}{\\partial \\sigma} &= -\\sum_{n=1}^N \n",
      "\\left ( \\frac{1}{2}\\frac{1}{\\sigma} +\n",
      "\\frac{1}{2} (x_n-\\mu)^2 (-1) \\sigma^{-2} \\right )\\\\\n",
      " &= \\frac{1}{2}\\sum_{n=1}^N \\left ( -\\frac{1}{\\sigma} + (x_n-\\mu)^2\n",
      " / \\sigma^2 \\right ) \\\\\n",
      " &= \\frac{1}{2}\\sum_{n=1}^N \\frac{-\\sigma + (x_n-\\mu)^2}{\\sigma^2}\n",
      "\\end{align*}\n",
      "$$\n",
      "Setting this equal to zero results in\n",
      "$$\n",
      "\\begin{align*}\n",
      "0  &= \\frac{1}{2}\\sum_{n=1}^N \\frac{-\\sigma + (x_n-\\mu)^2}{\\sigma^2}\\\\\n",
      " &= \\sum_{n=1}^N -\\sigma + (x_n-\\mu)^2\\\\\n",
      " &=  -N\\sigma + \\sum_{n=1}^N (x_n-\\mu)^2\\\\\n",
      "\\sigma &= \\frac{1}{N} \\sum_{n=1}^N (x_n-\\mu)^2\n",
      "\\end{align*}\n",
      "$$\n",
      "There we have the standard formulas for the mean and variance of a\n",
      "normal distribution.  ($\\sigma$ usually means standard deviation and\n",
      "$\\sigma^2$ is used for variance.)\n",
      "\n",
      "Of course for more than one dimension we get a $D$-dimensional vector\n",
      "for $\\muv$ and a $D\\times D$ matrix for the covariance.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's do it in python.\n",
      "\n",
      "Let's generate some data.  First, a little review.\n",
      "\n",
      "We can convert samples, $x$, from a univariate Normal distribution to\n",
      "samples, $z$, from a standard Normal distribution by \n",
      "$$\n",
      "\\begin{align*}\n",
      "z = \\frac{x-\\mu}{\\sigma}\n",
      "\\end{align*}\n",
      "$$\n",
      "We can generate samples, $x$, from samples $z$ from a standard Normal distribution.\n",
      "$$\n",
      "\\begin{align*}\n",
      "x = z \\sigma + \\mu\n",
      "\\end{align*}\n",
      "$$\n",
      "This is extended to multivariate Gaussians as\n",
      "$$\n",
      "\\begin{align*}\n",
      "\\zv & = (\\xv-\\muv)^T\\Sigmav^{-1/2}\\\\\n",
      "\\xv &= \\zv \\boldsymbol{L} + \\muv\n",
      "\\end{align*}\n",
      "$$\n",
      "where $\\boldsymbol{L}\\boldsymbol{L}^T = \\Sigmav$, found by Cholesky\n",
      "factorization. (See [documentation on *np.linalg.cholesky*](http://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.cholesky.html)).\n",
      "\n",
      "So, to generate two-dimensional samples from an arbitrary Normal\n",
      "distribution, first make samples $\\zv$, from a standard Normal distribution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def normald(X, mu, sigma):\n",
      "    \"\"\" normald:\n",
      "       X contains samples, one per row, N x D. \n",
      "       mu is mean vector, D x 1.\n",
      "       sigma is covariance matrix, D x D.  \"\"\"\n",
      "    D = X.shape[1]\n",
      "    detSigma = sigma if D == 1 else np.linalg.det(sigma)\n",
      "    if detSigma == 0:\n",
      "        raise np.linalg.LinAlgError('normald(): Singular covariance matrix')\n",
      "    sigmaI = 1.0/sigma if D == 1 else np.linalg.inv(sigma)\n",
      "    normConstant = 1.0 / np.sqrt((2*np.pi)**D * detSigma)\n",
      "    diffv = X - mu.T # change column vector mu to be row vector\n",
      "    return normConstant * np.exp(-0.5 * np.sum(np.dot(diffv, sigmaI) * diffv, axis=1))[:,np.newaxis]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nSamples = 50000\n",
      "xs = np.random.normal(0.0, 1.0, nSamples)\n",
      "ys = np.random.normal(0.0, 1.0, nSamples)\n",
      "X = np.vstack((xs,ys)).T\n",
      "X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now transform to samples $\\xv$ from a Normal distribution with $\\muv$\n",
      "and $\\Sigmav$.  This can also be done by calling [*np.random.multivariate_normal*](http://docs.scipy.org/doc/numpy/reference/routines.random.html)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Sigma = np.array([[1, 0.5], [0.5,0.4]])\n",
      "Sigma"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mu = np.array([5,8])\n",
      "mu"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "L = np.linalg.cholesky(Sigma)\n",
      "print(L)\n",
      "newX = np.dot(X,L.T) + mu\n",
      "newX"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's plot both the original samples, in red, and the transformed samples, in blue."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(   X[:,0],    X[:,1], 'ro', alpha=0.8)\n",
      "plt.plot(newX[:,0], newX[:,1], 'bo', alpha=0.8);\n",
      "plt.axis('equal');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, because we always check our calculations, we calculate\n",
      "the parameters that maximize the likelihood of the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nSamples = newX.shape[0]\n",
      "muEst = np.sum(newX,axis=0) / nSamples\n",
      "diff = newX - muEst\n",
      "vars = np.sum(diff * diff, axis=0) / (nSamples-1)\n",
      "covar = np.sum(diff[:,0] * diff[:,1]) / (nSamples-1)\n",
      "SigmaEst = np.array([[vars[0], covar], [covar, vars[1]]])\n",
      "# or \n",
      "#  muEst = np.mean(newX,axis=0)\n",
      "#  SigmaEst = np.cov(newX.T)\n",
      "\n",
      "print(\"Original mean\")\n",
      "print(mu)\n",
      "print(\"Estimated mean\")\n",
      "print(muEst)\n",
      "print(\"Original Sigma\")\n",
      "print(Sigma)\n",
      "print(\"Estimated Sigma\")\n",
      "print(SigmaEst)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's try out the new [ipython notebook *interact* feature](http://nbviewer.ipython.org/github/ipython/ipython-in-depth/blob/master/examples/Interactive%20Widgets/Using%20Interact.ipynb) to explore the spread of normally distributed points as the mean and covariance matrix are varied.  As you move the sliders you may encounter output with a line near the bottom that says\n",
      "\n",
      "    LinAlgError: Matrix is not positive definite\n",
      "    \n",
      "You have just selected values for the covariance matrix, $\\Sigma$, for which the matrix cannot be factored into $L L^T$. We must have positive definite matrices for valid covariance matrices.  Given a set of data, the sample covariance matrix will not satisfy this if at least one column is a linear function of one or more other columns.  For the following interaction, just move the slider back to where it was until a matrix is selected that does not produce the error."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.html.widgets import interact\n",
      "@interact(N=(2,1000), mux=(-10,10,0.1), muy=(-10,10,0.1), sigmax=(0.1,20,0.1), sigmay=(0.1,20,0.1), sigmaxy=(-10,10,0.1))\n",
      "\n",
      "def bunchOfData(N, mux, muy, sigmax, sigmay, sigmaxy):\n",
      "    plt.figure(figsize=(8,8))\n",
      "    xs = np.random.normal(0.0, 1.0, N)\n",
      "    ys = np.random.normal(0.0, 1.0, N)\n",
      "    X = np.vstack((xs,ys)).T\n",
      "    L = np.linalg.cholesky(np.array([[sigmax, sigmaxy],[sigmaxy, sigmay]]))\n",
      "    newX = np.dot(X,L.T) + [mux,muy]\n",
      "    plt.plot(newX[:,0], newX[:,1], 'bo', alpha=0.8);\n",
      "    plt.xlim(-15,15)\n",
      "    plt.ylim(-15,15);\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As discussed in our book, restricting the covariance matrix $\\Sigma$ to symmetric matrices does not limit us.  See Exercise 2.17 [and its answer](http://research.microsoft.com/en-us/um/people/cmbishop/PRML/).\n",
      "\n",
      "Let's play with the Old Faithful data set that our author provides [here](http://www-958.ibm.com/software/analytics/manyeyes/datasets/old-faithful-duration-min-by-interva/versions/1.txt)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wget http://www-958.ibm.com/software/analytics/manyeyes/datasets/old-faithful-duration-min-by-interva/versions/1.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head 1.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "dataframe = pandas.read_csv('1.txt',delimiter='\\t')\n",
      "dataframe[:5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataframe[['Interval','Duration']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = dataframe[['Interval','Duration']].values\n",
      "data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(data[:,0],data[:,1]);\n",
      "plt.xlabel('Interval');\n",
      "plt.ylabel('Duration');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Clearly a single Gaussian (or Normal) distribution will not model this data very well.  We need a way to find multiple Gaussians to model this.\n",
      "\n",
      "Imagine we have two Gaussian distributions, one with mean near (60,2) and the other near (95, 4.5).  If we just sum their values for a grid of points across the Interval x Duration plan, we should have two hills.  Now we need to figure out how to find the means and covariance matrices of these Gaussians."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}